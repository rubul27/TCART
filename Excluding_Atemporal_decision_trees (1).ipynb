{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disabled-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Bottleneck unit testing available.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conceptual-final",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe5aa367eb0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tsai/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe5aa041670>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tsai/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe5aa041d90>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tsai/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe5aa36e8e0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tsai/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe5aa2f79d0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tsai/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "stable = True # Set to True for latest pip version or False for main branch in GitHub\n",
    "!pip install {\"tsai -U\" if stable else \"git+https://github.com/timeseriesAI/tsai.git\"} >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vulnerable-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Linux-5.10.0-11-amd64-x86_64-with-glibc2.31\n",
      "python          : 3.9.2\n",
      "tsai            : 0.3.9\n",
      "fastai          : 2.7.15\n",
      "fastcore        : 1.5.33\n",
      "torch           : 2.2.2+cu121\n",
      "device          : cpu\n",
      "cpu cores       : 32\n",
      "threads per cpu : 1\n",
      "RAM             : 125.59 GB\n",
      "GPU memory      : N/A\n"
     ]
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "import sklearn.metrics as skm\n",
    "my_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southern-custody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 24, 51),\n",
       " (360,),\n",
       " ((#180) [0,1,2,3,4,5,6,7,8,9...],\n",
       "  (#180) [180,181,182,183,184,185,186,187,188,189...]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset id\n",
    "dsid ='NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "X.shape, y.shape, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "juvenile-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0', '2.0', '3.0', '4.0', '5.0', '6.0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occupied-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = []\n",
    "indexes = []\n",
    "for i in range(len(y)):\n",
    "  if y[i] == '2.0':\n",
    "    target_values.append(1)\n",
    "    indexes.append(i)\n",
    "  if y[i] == '3.0':\n",
    "    target_values.append(2)\n",
    "    indexes.append(i)\n",
    "  if y[i] == '4.0':\n",
    "     target_values.append(3)\n",
    "     indexes.append(i)\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "data = X[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dressed-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,:6,:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unlikely-ratio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 6, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opposed-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,target_values,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transsexual-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node initialization\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,feature=None, threshold=None,interval = None,relation =None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.interval = interval\n",
    "        self.relation = relation\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "# ALLEN RELATIONS       \n",
    "\n",
    "def allen_relation(interval1, interval2):\n",
    "    x, y = interval1\n",
    "    a, b = interval2\n",
    "\n",
    "    if y == a:\n",
    "        return \"A\"  # after\n",
    "    elif y < a:\n",
    "        return \"L\"  # later\n",
    "    elif x == a and b < y:\n",
    "        return \"B\"  # begins\n",
    "    elif y == b and x < a:\n",
    "        return \"E\"  # ends\n",
    "    elif x < a and b < y:\n",
    "        return \"D\"  # during\n",
    "    elif x < a < y < b:\n",
    "        return \"O\"  # overlaps\n",
    "    elif x == a and y < b:\n",
    "        return \"B_complement\"  # begins in\n",
    "    elif x > a and y < b:\n",
    "        return \"D_complement\"  # during in\n",
    "    elif a < x and b == y:\n",
    "        return \"E_complement\"  # ends in\n",
    "    elif a < x and x == b :\n",
    "        return \"A_complent\"  # during begins\n",
    "    elif a < b < x < y:\n",
    "        return \"L_complement\"  # ends begins\n",
    "    elif a< x < y < b:\n",
    "        return \"O_complement\"  # ends overlaps\n",
    "    else:\n",
    "        return \"NoÂ relation\"\n",
    "\n",
    "# CHECKING THRESHOLD \n",
    "\n",
    "def check_values_greater_than_threshold(lst, threshold, percentage):\n",
    "    count_greater = sum(1 for value in lst if value > threshold)\n",
    "    return count_greater / len(lst) >= percentage\n",
    "\n",
    "def generate_all_intervals(t):\n",
    "    intervals = []\n",
    "    for start in range(t-4):  # Ensure the interval has 5 timestamps\n",
    "\n",
    "        intervals.append((start, start+5))\n",
    "\n",
    "    return intervals\n",
    "\n",
    "#INFORMATION GAIN\n",
    "\n",
    "def gini_impurity(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / len(y)\n",
    "    return - np.sum(probs*np.log(probs))\n",
    "\n",
    "def information_gain(y, y_left, y_right):\n",
    "\n",
    "    p = len(y_left) / len(y)\n",
    "    gini_parent = gini_impurity(y)\n",
    "    gini_children = p * gini_impurity(y_left) + (1 - p) * gini_impurity(y_right)\n",
    "    return gini_parent - gini_children\n",
    "\n",
    "# GENERATING TIME INTERVALS FOR TIME SERIES\n",
    "\n",
    "def generate_all_intervals(t):\n",
    "    intervals = []\n",
    "    for start in range(t-7):  # Ensure the interval has 8 timestamps\n",
    "\n",
    "        intervals.append((start, start+8))\n",
    "\n",
    "    return intervals\n",
    "\n",
    "# FINDING THE BEST DECISIONS FOR SPLITTING\n",
    "\n",
    "def findBestDecision_and_split(data, target_values,poss_intervals=generate_all_intervals(30)):\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_interval = None\n",
    "    max_information_gain = -1\n",
    "    best_rel = None\n",
    "\n",
    "    Te = None\n",
    "    Tu = None\n",
    "    left_target = None\n",
    "    right_target = None\n",
    "\n",
    "\n",
    "    for feature in range(data.shape[1]):\n",
    "      unique_values_array = []\n",
    "      for i in range(data.shape[0]):\n",
    "          sample = data[i,feature, :]  # Extract the i-th sample\n",
    "          unique_values = np.unique(sample)  # Find the unique  values for the current sample\n",
    "          unique_values_array.append(unique_values)\n",
    "          thresholds = []\n",
    "          for row in unique_values_array:\n",
    "              thresholds.extend(list(row))\n",
    "\n",
    "      for j in range(len(possible_intervals)):\n",
    "\n",
    "            ref_interval = possible_intervals[j]\n",
    "\n",
    "\n",
    "            for relation in relations:\n",
    "\n",
    "              after_intervals = [(a, b) for a, b in possible_intervals if allen_relation(ref_interval, (a, b)) == relation]\n",
    "\n",
    "\n",
    "              for threshold in thresholds:\n",
    "\n",
    "                    left_data = []\n",
    "                    left_y = []\n",
    "                    right_data = []\n",
    "                    right_y = []\n",
    "\n",
    "\n",
    "                    for i in range(len(data)):\n",
    "\n",
    "\n",
    "                        int_values = [data[i][feature][interval[0]:interval[1]+1] for interval in after_intervals]\n",
    "\n",
    "\n",
    "                        if any(check_values_greater_than_threshold(lst,threshold, 0.75) for lst in int_values):\n",
    "                            left_data.append(data[i])\n",
    "                            left_y.append(target_values[i])\n",
    "\n",
    "                        else:\n",
    "                            right_data.append(data[i])\n",
    "                            right_y.append(target_values[i])\n",
    "\n",
    "\n",
    "                    inf_gain = information_gain(target_values,left_y, right_y)\n",
    "\n",
    "\n",
    "                    if inf_gain > max_information_gain:\n",
    "\n",
    "                            best_interval = ref_interval\n",
    "                            max_information_gain = inf_gain\n",
    "                            best_threshold = threshold\n",
    "                            best_rel = relation\n",
    "                            best_feature = feature\n",
    "                            Te = left_data\n",
    "                            Tu = right_data\n",
    "                            left_target = left_y\n",
    "                            right_target = right_y\n",
    "\n",
    "\n",
    "                        # print(len(left_target),len(right_target))\n",
    "\n",
    "    return best_feature,best_interval,best_threshold,best_rel,np.array(Te),np.array(Tu),left_target,right_target,max_information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generic-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLeafNode(target_values):\n",
    "    if len(target_values) == 0:\n",
    "        # Return a default value when target_values is empty\n",
    "        return Node(value = None)\n",
    "    else:\n",
    "        # Return the most common target value\n",
    "        return Node(value=np.argmax(np.bincount(list(target_values))))\n",
    "\n",
    "def CreateNode(data):\n",
    "    return Node()\n",
    "\n",
    "def Learn(data,target_values,poss_intervals=generate_all_intervals(30),max_depth=8, current_depth=0):\n",
    "\n",
    "    if len(target_values) == 0 :\n",
    "        return CreateLeafNode(target_values)\n",
    "    if len(np.unique(target_values)) == 1 or max_depth <= current_depth or poss_intervals ==[] or relations ==[] :\n",
    "        return CreateLeafNode(target_values)\n",
    "\n",
    "\n",
    "    best_feature,best_interval,best_threshold,best_rel,Te,Tu,left_target,right_target,max_information_gain = findBestDecision_and_split(data, target_values,poss_intervals=generate_all_intervals(30))\n",
    "\n",
    "    node = CreateNode(data)\n",
    "    node.feature = best_feature\n",
    "    node.threshold = best_threshold\n",
    "    node.interval = best_interval\n",
    "    node.relation = best_rel\n",
    "\n",
    "    print(\"Left tree shape : \",Te.shape)\n",
    "    print(\"Target values in the left tree : \",left_target)\n",
    "    print('*******************************')\n",
    "    print(\"Right tree shape : \",Tu.shape)\n",
    "    print(\"Target values in the right tree : \",right_target)\n",
    "    print(\"Feature number used : \",best_feature,\"\\nBest Interval : \",best_interval,\", Best relation : \",best_rel,\", Best Threshold : \",best_threshold)\n",
    "    print('__________________________________________________________________________')\n",
    "    print()\n",
    "\n",
    "    node.left = Learn(Te,left_target,poss_intervals = generate_all_intervals(30) ,max_depth = 8,current_depth = current_depth + 1)\n",
    "    node.right = Learn(Tu,right_target,poss_intervals = generate_all_intervals(30),max_depth = 8 ,current_depth = current_depth+1)\n",
    "\n",
    "    return node\n",
    "\n",
    "def TCART(data,target_values,poss_intervals,relations):\n",
    "\n",
    "    tau = Node()\n",
    "\n",
    "    tau = Learn(data,target_values,poss_intervals,max_depth=8, current_depth=0)\n",
    "    return tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hydraulic-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relations = [\"A\",\"L\",\"B\",\"E\",\"D\",\"O\",\"B_complement\",\"D_complement\",\"E_complement\",\"A_complent\",\"L_complement\",\"O_complement\"]\n",
    "possible_intervals = generate_all_intervals(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left tree shape :  (37, 6, 40)\n",
      "Target values in the left tree :  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "*******************************\n",
      "Right tree shape :  (83, 6, 40)\n",
      "Target values in the right tree :  [1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2]\n",
      "Feature number used :  0 \n",
      "Best Interval :  (0, 8) , Best relation :  L , Best Threshold :  -0.317034\n",
      "__________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree  = TCART(X_train,y_train,poss_intervals = generate_all_intervals(40) ,relations=[\"A\",\"L\",\"B\",\"E\",\"D\",\"O\",\"B_complement\",\"D_complement\",\"E_complement\",\"A_complent\",\"L_complement\",\"O_complement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, sample):\n",
    "    if node.value is not None:\n",
    "\n",
    "        return node.value\n",
    "    feature = node.feature\n",
    "    threshold = node.threshold\n",
    "    interval = node.interval\n",
    "    relation = node.relation\n",
    "    left = node.left\n",
    "    right = node.right\n",
    "   # value = node.value\n",
    "\n",
    "    after_intervals = [(a, b) for a, b in possible_intervals if allen_relation(interval, (a, b)) == relation]\n",
    "    int_values = [sample[feature][interval[0]:interval[1]+1] for interval in after_intervals]\n",
    "\n",
    "\n",
    "    if any(check_values_greater_than_threshold(lst,threshold, 0.75) for lst in int_values):\n",
    "        return predict(node.left, sample)\n",
    "    else:\n",
    "        return predict(node.right, sample)\n",
    " \n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Iterate over each sample in the test data\n",
    "for sample in X_test:\n",
    "    # Predict the target variable for the sample using the decision tree 'tau'\n",
    "    predicted_value = predict(tree,sample)\n",
    "    predictions.append(predicted_value)\n",
    "\n",
    "# Convert predictions to a numpy array\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test,predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "precision = precision_score(y_test, predictions, average= None)\n",
    "recall = recall_score(y_test, predictions, average=None)\n",
    "f1 = f1_score(y_test, predictions, average=None)\n",
    "\n",
    "print(\"Precision :\",precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"F1 Score :\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-brunswick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-height",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
